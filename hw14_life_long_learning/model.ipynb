{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOtXcnP++TjKsW1N8e+yOHc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"6YFORvIg5rux","colab_type":"code","colab":{}},"source":["class Model(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.fc1=nn.Linear(3*32*32,1024)\n","    self.fc2=nn.Linear(1024,512)\n","    self.fc3=nn.Linear(512,256)\n","    self.fc4=nn.Linear(256,128)\n","    self.fc5=nn.Linear(128,128)\n","    self.fc6=nn.Linear(128,10)\n","    self.relu=nn.ReLU()\n","\n","  def forward(self,x):\n","    x=x.view(x.shape[0],-1)\n","    x=self.fc1(x)\n","    x=self.relu(x)\n","    x=self.fc2(x)\n","    x=self.relu(x)\n","    x=self.fc3(x)\n","    x=self.relu(x)\n","    x=self.fc4(x)\n","    x=self.relu(x)\n","    x=self.fc5(x)\n","    x=self.relu(x)\n","    x=self.fc6(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yYECLPzS6cZI","colab_type":"code","colab":{}},"source":["class EWC(object):\n","  \"\"\"\n","    @article{kirkpatrick2017overcoming,\n","        title={Overcoming catastrophic forgetting in neural networks},\n","        author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},\n","        journal={Proceedings of the national academy of sciences},\n","        year={2017},\n","        url={https://arxiv.org/abs/1612.00796}\n","    }\n","  \"\"\"\n","  def __init__(self, model: nn.Module, dataloaders: list, device):\n","    \n","    self.model = model\n","    self.dataloaders = dataloaders\n","    self.device = device\n","    \n","    self.params = {n: p for n, p in self.model.named_parameters() if p.requires_grad} #抓出模型的所有參數\n","    self._means = {} # 初始化 平均參數\n","    self._precision_matrices = self._calculate_importance() # 產生 EWC 的 Fisher (F) 矩陣 \n","    \n","    for n, p in self.params.items():\n","      self._means[n] = p.clone().detach() # 算出每個參數的平均 （用之前任務的資料去算平均）\n","    \n","  def _calculate_importance(self):\n","    print('Computing EWC')\n","    \n","    precision_matrices={}\n","    for n,p in self.params.items():\n","      precision_matrices[n]=p.clone().detach().fill_(0)\n","\n","    self.model.eval()\n","    dataloader_num=len(self.dataloaders)\n","    number_data=sum([len(loader) for loader in self.dataloaders])\n","    for dataloader in self.dataloaders:\n","      for data in dataloader:\n","        self.model.zero_grad()\n","        input=data[0].to(self.device)\n","        output=self.model(input).view(1,-1)\n","        label=output.max(1)[1].view(-1)\n","\n","        loss=F.nll_loss(F.log_softmax(output,dim=1),label)\n","        loss.backward()\n","\n","        for n,p in self.model.named_parameters():\n","          precision_matrices[n].data+=p.grad.data**2/number_data\n","\n","    precision_matrices={n:p for n,p in precision_matrices.items()}\n","    return precision_matrices\n","\n","  def penalty(self,model:nn.Module):\n","    loss=0\n","    for n,p in model.named_parameters():\n","      _loss=self._precision_matrices[n]*(p-self._means[n])**2\n","      loss+=_loss.sum()\n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Amal2R3D-Qwe","colab_type":"code","colab":{}},"source":["class MAS(object):\n","    \"\"\"\n","    @article{aljundi2017memory,\n","      title={Memory Aware Synapses: Learning what (not) to forget},\n","      author={Aljundi, Rahaf and Babiloni, Francesca and Elhoseiny, Mohamed and Rohrbach, Marcus and Tuytelaars, Tinne},\n","      booktitle={ECCV},\n","      year={2018},\n","      url={https://eccv2018.org/openaccess/content_ECCV_2018/papers/Rahaf_Aljundi_Memory_Aware_Synapses_ECCV_2018_paper.pdf}\n","    }\n","    \"\"\"\n","    def __init__(self,model:nn.Module,dataloaders:list,device):\n","      self.model=model\n","      self.dataloaders=dataloaders\n","      self.params={n:p for n,p in self.model.named_parameters() if p.requires_grad}\n","      self._means={}\n","      self.device=device\n","      self._precision_matrices=self._calculate_importance()\n","\n","      for n,p in self.params.items():\n","        self._means[n]=p.clone().detach()\n","\n","    def _calculate_importance(self):\n","      print('Computing MAS')\n","\n","      precision_matrices={}\n","      for n,p in self.params.items():\n","        precision_matrices[n]=p.clone().detach().fill_(0)\n","      \n","      self.model.eval()\n","      dataloader_num=len(self.dataloaders)\n","      num_data=sum([len(loader) for loader in self.dataloaders])\n","      for dataloader in self.dataloaders:\n","        for data in dataloader:\n","          self.model.zero_grad()\n","          output=self.model(data[0].to(self.device))\n","          output.pow_(2)\n","          loss=torch.sum(output,dim=1)\n","          loss=loss.mean()\n","          loss.backward()\n","\n","          for n,p in self.model.named_parameters():\n","            precision_matrices[n].data+=p.grad.abs()/num_data\n","      precision_matrices={n:p for n,p in precision_matrices.items()}\n","      return precision_matrices\n","    \n","    def penalty(self,model:nn.Module):\n","      loss=0\n","      for n,p in model.named_parameters():\n","        _loss=self._precision_matrices[n]*(p-self._means[n])**2\n","        loss+=_loss.sum()\n","      return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p4cGwS_1EW2g","colab_type":"code","colab":{}},"source":["class SCP(object):\n","  \"\"\"\n","    OPEN REVIEW VERSION:\n","    https://openreview.net/forum?id=BJge3TNKwH\n","  \"\"\"\n","  def __init__(self,model:nn.Module,dataloaders:list,L:int,device):\n","    self.model=model\n","    self.dataloaders=dataloaders\n","    self.params={n:p for n,p in self.model.named_parameters() if p.requires_grad}\n","    self._means={}\n","    self.L=L\n","    self.device=device\n","    self._precision_matrices=self.calculate_importance()\n","\n","    for n,p in self.params.items():\n","      self._means[n]=p.clone().detach()\n","\n","  def calculate_importance(self):\n","    print('Computing SCP')\n","\n","    precision_matrices={}\n","    for n,p in self.params.items():\n","      precision_matrices[n]=p.clone().detach().fill_(0)\n","\n","    self.model.eval()\n","    dataloader_num=len(self.dataloaders)\n","    num_data=sum([len(loader) for loader in self.dataloaders])\n","    vector=0.\n","    for dataloader in self.dataloaders:\n","      for data in dataloader:\n","        self.model.zero_grad()\n","        output=self.model(data[0].to(self.device)) #(256,10)\n","        vector+=output.sum(dim=0)/num_data #(10)   \n","\n","    sigmas=torch.tensor(sample_spherical(self.L,ndim=10),dtype=torch.float32).to(device)   #(10,self.L)\n","    for l in range(self.L):\n","      self.model.zero_grad()\n","      ro=torch.dot(sigmas[:,l],vector)   #(1)\n","      ro.backward(retain_graph=True)\n","\n","      for n,p in self.model.named_parameters():\n","        precision_matrices[n].data+=p.grad.data**2/self.L\n","\n","    precision_matrices={n:p for n,p in precision_matrices.items()}\n","    return precision_matrices\n","\n","  def penalty(self,model:nn.Module):\n","    loss=0\n","    for n,p in model.named_parameters():\n","      _loss=self._precision_matrices[n]*(p-self._means[n])**2\n","      loss+=_loss.sum()\n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IT5DxKLjfLaL","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}